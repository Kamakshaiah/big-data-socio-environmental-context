db,sn,Abstract
S,1,"Purpose: This study conducts a systematic review using 452 academic and industry articles from an initial set of 60,899 records obtained by 3 databases from 2012 to 2020. The authors compare and contrast blockchains with existing legacy systems. The authors identify existing regulation, accounting standards, guidelines and potential amendments in under-explored areas such as taxation, accounting treatment of crypto-assets/liabilities and detailed auditing procedures. The study aims to highlight the trends, differences and gaps between academic and industry literature. The authors provide a behavioral, social, cultural, organizational, regulatory, ethical, accountability and managerial perspectives of blockchain adoption in accounting. Finally, the study develops two adoption frameworks. Design/methodology/approach: The authors' study follows (Moher et al., 2009) and (Briner and Denyer, 2012) methodology to conduct the systematic review and the steps are mentioned below. The authors construct a final sample of 452 from a preliminary search of three multi-disciplinary databases from 2012 to 2020. First, the authors motivate the review and formulate the research questions. Second, the authors aggregate relevant literature from both industry and academia and implement quality assessments. Third, the authors analyze the literature and construct the final sample of articles. Fourth, the authors conducted textual analysis, keyword frequencies and identify gaps, trends and similarities between academic and industry literature and develop the authors' frameworks Findings: The authors identify 3 (ABDC, B and A* ranked) journals as publishing top article numbers with the highest article count for 2017 with 96 articles in academia and 2019 for the industry with 21 articles. Second-highest publications for academia occur in 2018 with 77 followed by, whereas in the industry, publications occur in the year 2016 with 16 articles. Two co-authors appear most popular with 103 articles. Word clouds, a mind map and article theme counts are used to identify nine key research clusters: data management, financial applications, sustainability, accounting and auditing, business and industrial, education, governance, privacy/security and disruptive technology. Research limitations/implications: Systematic reviews can have selection biases mainly due to search and selection criteria distortions when constructing the final sample of articles. The authors address selection bias by refining our search keyword combinations by using different permutations and using keywords from articles already collected. The authors employ three databases and review the reference list of articles collected to add more articles that may have been missed into our sample. In addition, to avoid inconsistent coding of domains/themes and interpretations, the authors carefully review our domain identifications and all our analysis twice independently using two research assistants to obtain the same conclusions. Practical implications: The authors' unique contributions include reviewing additional papers, differentiating between industry, academic articles, common trends and gaps in much scattered prior literature. The authors identify existing accounting standards, guidelines, limitations and possible amendments required in future for blockchain adoption in accounting in taxation, accounting treatment of crypto-assets/liabilities and detailed audit procedures. Blockchains are compared with legacy accounting technologies and two frameworks for adoption developed. The authors' results could impact the understanding of existing regulation, accounting standards, future amendments, areas requiring clarity and future collaborative research between academia and industry across multi-disciplines. Practical implications to academics, professional bodies, regulators and industry practitioners exist. Social implications: The authors' study identifies significant implications on organizations, environment, culture and society in general. The authors identify that social engagement projects may be easily initiated and implemented with decentralized accounting information systems. Transparency and efficiency would change organization culture, ways accountants and even employees interact with each other and community. Anonymity in blockchains can be used for criminal activities. Coding of negative social dynamics to smart contracts may persist. Transparency of personally identifiable information may place individuals at risk. Regulation and standards would need to identify equity, ethics in blockchains which notwithstanding energy consumption, and could enable environmental protection increasing societal sustainability. Originality/value: To the authors' knowledge, this is the first study that compares academic and industry literature of 452 articles to identify gaps and similarities from 2012 to 2020 using three multi-disciplinary databases. The authors' study is the first study to in detail existing accounting standards, unclear areas, future amendments for International Financial Reporting Standards (IFRS) standards on taxation, financial reporting and all aspects of auditing procedures. The authors further categorize prior literature into these key areas and develop two frameworks (DAERPS and DAIS) that are linked to our review results and prior literature. The authors identify the impact of blockchain adoption on key stakeholders, regulation, society, culture, organization, accountability and ethics. © 2022, Emerald Publishing Limited."
S,2,"Environmental problems in China are urgent so that resource and environmental auditing is becoming more and more important. The objectives of this study are to introduce spatial and emerging information technologies and its applications in resource and environmental auditing. We synthesized characteristics and advantages of GIS applications and auditing application cases, implemented by National Audit Office of P. R. China, Nanjing Branch and Wuhan Branch, from the practice perspective. In the future, spatial information technology combining with emerging information technologies, including Big Data, Internet of Things, Cloud Computing, Augmented Reality (AR) Technique, large distributed and mobile network will improve the reliability of audit evidences and enhance the auditing conclusions and functions, especially resource and environmental auditing. © Springer-Verlag Berlin Heidelberg 2013."
S,3,"Assuring future performance of systems-of-systems through advanced-technology investments is a perpetual challenge of industry and agencies. Among the complicating factors are technology innovation, escalating scales, and diversity of software and hardware applications, increasing availability and scrutiny of big data, and evolving business, environmental, and legal contexts. These factors are engaging system owner/operators to continually reprioritize these investments, even as transparent principles for investment are needed for appropriate oversight and auditing. In this paper, a branch of resilience analysis offers to address multiple layers of uncertainty that arise from technology plans around future disruptions to large-scale systems-of-systems. The paper presents a methodology to quantify and manage the disruptive influence of individual systems perspectives to the prioritization of technology investments across the system-of-systems. The methodology is demonstrated through a case study on an information technology investment portfolio of the US Department of Commerce, USA. The experience suggests how fiscal limitations, combining with several other factors, has the largest disruption to the prioritization of investments. The results furthermore describe how investments perform relative to one another and characterize where the system-of-systems might be resilient to the perspectives of constituent systems. Abbreviations: BEA: Bureau of Economic Analysis; BIS: Bureau of Industry and Security; DOC: United States Department of Commerce; FY: Fiscal Year; IT: Information Technology; MCDA: Multicriteria Decision Analysis; NOAA: National Oceaic and Atmospheric Administration; NTIA: National Telecommunications and Information Administration; USPTO: United States Patent and Trademark Office. © 2019 Informa UK Limited, trading as Taylor & Francis Group."
S,4,"The use real-time analysis of big data necessitates auditors modify their evidence-gathering procedures of employing continuous auditing in assuring sustainability attributes. We suggest a model that integrates assurance and its continuous auditing into all five economic, governance, social, ethical and environmental (EGSEE) dimensions of sustainability performance reporting. Real-time analysis of big data facilitates more transparent and timely available information for auditors to perform procedures provide reasonable assurance on accuracy, consistency and completeness of information. Big Data is often referred to as electronic data and is the capability of accessing, analysing, and assessing a huge amount of data and transforming them into information in a timely manner for decision making. The application of Big Data and Data Science Analytics to auditing is currently at an early stage. This study examines the real-time analysis of big data, which including evidence-gathering procedures and tests on audit and assurance services for sustainability attributes. We provide policy, practical and educational implications of employing real-time analysis of big data for sustainability performance as the implementation of continues auditing."
S,5,"Purpose: This study conducts a systematic review using 452 academic and industry articles from an initial set of 60,899 records obtained by 3 databases from 2012 to 2020. The authors compare and contrast blockchains with existing legacy systems. The authors identify existing regulation, accounting standards, guidelines and potential amendments in under-explored areas such as taxation, accounting treatment of crypto-assets/liabilities and detailed auditing procedures. The study aims to highlight the trends, differences and gaps between academic and industry literature. The authors provide a behavioral, social, cultural, organizational, regulatory, ethical, accountability and managerial perspectives of blockchain adoption in accounting. Finally, the study develops two adoption frameworks. Design/methodology/approach: The authors' study follows (Moher et al., 2009) and (Briner and Denyer, 2012) methodology to conduct the systematic review and the steps are mentioned below. The authors construct a final sample of 452 from a preliminary search of three multi-disciplinary databases from 2012 to 2020. First, the authors motivate the review and formulate the research questions. Second, the authors aggregate relevant literature from both industry and academia and implement quality assessments. Third, the authors analyze the literature and construct the final sample of articles. Fourth, the authors conducted textual analysis, keyword frequencies and identify gaps, trends and similarities between academic and industry literature and develop the authors' frameworks Findings: The authors identify 3 (ABDC, B and A* ranked) journals as publishing top article numbers with the highest article count for 2017 with 96 articles in academia and 2019 for the industry with 21 articles. Second-highest publications for academia occur in 2018 with 77 followed by, whereas in the industry, publications occur in the year 2016 with 16 articles. Two co-authors appear most popular with 103 articles. Word clouds, a mind map and article theme counts are used to identify nine key research clusters: data management, financial applications, sustainability, accounting and auditing, business and industrial, education, governance, privacy/security and disruptive technology. Research limitations/implications: Systematic reviews can have selection biases mainly due to search and selection criteria distortions when constructing the final sample of articles. The authors address selection bias by refining our search keyword combinations by using different permutations and using keywords from articles already collected. The authors employ three databases and review the reference list of articles collected to add more articles that may have been missed into our sample. In addition, to avoid inconsistent coding of domains/themes and interpretations, the authors carefully review our domain identifications and all our analysis twice independently using two research assistants to obtain the same conclusions. Practical implications: The authors' unique contributions include reviewing additional papers, differentiating between industry, academic articles, common trends and gaps in much scattered prior literature. The authors identify existing accounting standards, guidelines, limitations and possible amendments required in future for blockchain adoption in accounting in taxation, accounting treatment of crypto-assets/liabilities and detailed audit procedures. Blockchains are compared with legacy accounting technologies and two frameworks for adoption developed. The authors' results could impact the understanding of existing regulation, accounting standards, future amendments, areas requiring clarity and future collaborative research between academia and industry across multi-disciplines. Practical implications to academics, professional bodies, regulators and industry practitioners exist. Social implications: The authors' study identifies significant implications on organizations, environment, culture and society in general. The authors identify that social engagement projects may be easily initiated and implemented with decentralized accounting information systems. Transparency and efficiency would change organization culture, ways accountants and even employees interact with each other and community. Anonymity in blockchains can be used for criminal activities. Coding of negative social dynamics to smart contracts may persist. Transparency of personally identifiable information may place individuals at risk. Regulation and standards would need to identify equity, ethics in blockchains which notwithstanding energy consumption, and could enable environmental protection increasing societal sustainability. Originality/value: To the authors' knowledge, this is the first study that compares academic and industry literature of 452 articles to identify gaps and similarities from 2012 to 2020 using three multi-disciplinary databases. The authors' study is the first study to in detail existing accounting standards, unclear areas, future amendments for International Financial Reporting Standards (IFRS) standards on taxation, financial reporting and all aspects of auditing procedures. The authors further categorize prior literature into these key areas and develop two frameworks (DAERPS and DAIS) that are linked to our review results and prior literature. The authors identify the impact of blockchain adoption on key stakeholders, regulation, society, culture, organization, accountability and ethics. © 2022, Emerald Publishing Limited."
S,6,"Big data is the huge amount of data that is continuously produced by tools and technologies such as credit cards and customer loyalty cards, Internet and social media, Wi-Fi sensors, and electronic tagging. This study aims to review the literature on big data analysis and its integration in the accounting process. The study uses the secondary research to do a systematic review of the literature on big data analysis in the accounting profession. Despite the relative growth of technology in the accounting profession and extensive research in the big data analysis field, there are not enough academic review studies on using big data analysis in accounting. This chapter clarifies the issue of big data analysis in accounting and the opportunities that arise from it. The findings show that big data can improve accounting in several areas including data asset valuation, decision-making, risk management, and internal and independent auditing. The findings draw some implications for using big data analysis to enhance sustainability accounting in tropics. © 2022 selection and editorial matter, Jacob Wood, Taha Chaiechi and K Thirumaran; individual chapters, the contributors."
S,7,"Purpose: This study aims to provide an empirically informed view on the auditing profession’s readiness to embrace “disruptive” technologies. Relying on evidence from Big 4 employees in Italy, this study examines the factors that motivate auditors to use blockchain technology (BT). Design/methodology/approach: To this aim, this study uses an integrated theoretical frame merging the third version of the technology acceptance model (TAM3) and the unified theory of acceptance and use of technology (UTAUT). The analytical model is based on an application of the structural equation modelling with partial least square estimation on data gathered through a Likert-based questionnaire. Findings: The findings reveal that the main predictors of auditors’ intention to use blockchain are performance expectancy and social influence. Moreover, auditors’ effort expectancy in relation to this technology implementation and use appears to be a reasonably reliable predictor. Originality/value: This paper contributes an evidence-based view to the discussion on the impact of automation and disruptive information and communication technologies, on the roles of accounting and auditing professionals. It uses a novel approach to analysis by integrating TAM3 and UTAUT within its theoretical model. It complements and extends the field of studies on technology acceptance by offering fresh insights into auditors’ perceptions. Finally, the paper highlights practical implications for business leaders aiming to use the advantages of BT in audit firms. © 2020, Emerald Publishing Limited."
S,8,"The widespread application of big data has had a profound impact on social and economic development. Government auditing is the guarantee for the modernization of national governance, and the development of big data audit capability has become the key to improving national governance capability. This paper summarizes the concept of government audit big data capability, and constructs the influencing factor model of government audit big data capability. This study finds that the construction degree of audit big data platform, big data management ability, big data audit technology and auditors' big data technology ability have a significant positive impact on the government audit big data ability, and the audit organization coordination ability plays a positive moderating effect in the whole impact process. This study provides guidance for the improvement and development of government audit big data capability.  © 2021 ACM."
S,9,"Social networks, smartphones, mobile applications.. produce an avalanche of data on a large-scale and in an unstructured way. The phenomenon Big Data was born in order to address the different challenges including data storing, data analysis, data querying and so on. Technological advances always carry new security vulnerabilities that are not taken into consideration at the beginning. Security aspects usually require time to be addressed. The information system security is the set of measures to prevent any failure or threat including unauthorized accesses. Perfect protection must contain the four basic building blocks that are: authentication, access control, auditing, and encryption. In our work, we are specifically interested in access control. We first analyze the well-known access control models that were applied to Big Data. We then investigate the most important security projects. Most of these approaches and projects rely mainly on coarse-grained access control policies. In this work, we propose a novel approach called H-RCBAC that relies on two known models: the role-based access control (RBAC) and the content-based access control (CBAC). H-RCBAC is a new architecture that refines the access control process by considering a set of taboo words to guarantee fine-grained access control. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd."
S,10,"The UK audit profession is facing a crisis of public trust and legitimacy following a series of high-profile audit failures. This resulted in the executive leadership of UK audit firms being summoned before a House of Commons Select Committee as part of its inquiry into ‘the future of audit’. During this inquiry the audit executives walked a tightrope, to both defend the social contract from an existential threat and attempt to influence policy reforms in their favour. This paper draws on ‘neutralisation techniques’ from deviance theory and the ‘grammar of legitimation’ from legitimacy theory to inform a discursive analysis of how auditors use strategic rhetoric to defend their professionalism and maintain their social contract to operate, all the while attempting to affect policy outcomes to align with their firms’ economic interests. Data for this study are drawn from the ‘oral evidence sessions’ and submitted ‘written evidence’ provided by the audit firm leadership. Our findings illustrate how the auditors construct a variety of strategic rationalisations, couched in moral ideals, to effectively deny responsibility for corporate financial scandals while simultaneously identifying with the ‘victims’ of audit failures and representing themselves ‘heroically’, as indispensable solution-bearers, not problem-causers. Their application of logic and language is cleverly designed to defend existing practices, neutralize the allegations of the inquiry, and provide the basis for advocating preferred policy outcomes. We show how, in this UK regulatory context, the Big Four are again successful in diluting and delaying reform, especially that which would legislate a full legal and economic split of their lucrative advisory service business from their audit business - a union which has grown in prominence in recent decades and been the focus of accusations of conflicted interests detrimental to audit quality. Evaluating legitimacy as a rhetorical and communicative process can aid regulators to render visible the means by which auditors use rhetoric to influence reform, and thereby improve democratic oversight over the profession. © 2023 Elsevier Ltd"
S,11,"Public sector accounting reforms have resulted in crucial changes in accounting reporting by the government, namely the adoption of accrual accounting in the public sector. This study looks into the social factors that led to the Indonesian central government implementing accrual accounting reform. This study adopted a quantitative approach using purposive sampling. Structural Equation Modeling (SEM) with PLS version 3.0 was used to analyze the data. The information for this study was gathered using a Google Form, which was used to send 70 questionnaires to government finance officials, chief accountants and auditors, and heads of accounting and auditing divisions in the Ministry of Finance. Seeing these social factors is expected to increase the effectiveness of the administration of accrual accounting implementation. The results showed that pressure from donors, pressure from the National Board of Accountants and Auditors (NBAA), political will, and audit process had an impact on the effectiveness of accrual accounting application (AAA). However, management change, regulatory matters, and a culture of transparency have no effect. In addition, the effective administration of AAA affects managerial accountability. This study implies that the effective application of accrual accounting depends on human-related concerns and culture. It is important to note that accrual accounting is more of a management reform that entails changes to bigger areas of institutional and accountability systems than merely adopting a new accounting technology. © Revista Espanola de Investigacion Criminologica 2021."
S,12,"Financial reporting and assurance in their current form are losing relevance to investors in firm valuations. New sources of data, especially exogenous or external data that are generated outside the organizations, have opened doors to new ways of business measurement and information validation. Examples of exogenous data include social media, online searches, social networks, and news media. This paper discusses the state-of-the-art applications of exogenous data in the measurement and assurance of business reporting, ESG, and cybersecurity and provides potential avenues for future research. Furthermore, this paper speculates on the nature of the new paradigm of business measurement and assurance with exogenous data and the difficulties that are emerging. © 2022, American Accounting Association. All rights reserved."
S,13,"With the continuous complexity of China's market economic environment and the increasing role of social audits, there are an increasing number of audit risk problems, and research on this topic is increasingly important. Based on the above background, a social audit risk statistical method based on machine learning under the background of big data is proposed. Under the guidance of the index principle, this method selects the social audit risk statistical index and constructs the index system. Using the analytic hierarchy process, calculate the weight of social audit risk statistical indicators. The self-organizing feature mapping neural network in machine learning is used to construct the risk statistical model and complete the risk quantitative analysis. The experimental results show that under the application of the research method, the error between the social audit risk statistical results and the actual result is very small, which shows that the statistical accuracy of the research method is high and has wide application prospects.  © 2021 IEEE."
S,14,"The article presents the characteristic features of the introduction of digital technologies in the modern sector of cooperation, taking into account the trends in the development of the economy. In the context of differences in the possibilities of modernizing the cooperative sector, the authors examine the significance and problems of the development of accounting and analysis. The exhaustion of traditional opportunities for the development of the industry through the introduction of modern digital technologies, which are based on the low cost of labour, is stated. The content, essence, and basic principles of the innovative way of development of the cooperative sector are substantiated. It’s shown that the key issue related to the prospects for the further development of the cooperative sector in Russia, increasing the efficiency of using its resource potential is the introduction and use of new automated systems and tools in the context of the digitalization of the economy. Today digitalization is one of the key components in the development of the economy, affecting various spheres of life in modern society. The methodological base of the research includes the theory of accounting and auditing, as well as the principles of blockchain technologies in the aspect of their application in finance. This article provides an overview of the main trends in the development of blockchain technology in accounting and auditing based on foreign scientific articles, as well as an analysis of blockchain technologies in the area of forming the accounting policy of an organization. Conclusions about the degree of applicability of this technology in a modern organization are drawn; the main problems, risks, and benefits from the introduction of this technology are reflected. The results of the study are intended for developers of IT technologies and specialists of accounting and analytical profile and should contribute to improving the efficiency of systems for processing and exchanging big data in the area of economics. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG."
W,15,"Cloud-assisted applications have been developed in recent years, especially in servicing the smart city. Cloud computing is an emerging technology, which combines many redundant and distributed servers to provide various applications and services. On the one hand, the users can outsource their data to the cloud and enjoy the services that are provided by the cloud anytime and anywhere. On the other hand, outsourcing the data to the cloud will reduce the local storage burden and alleviate the hardware maintenance. However, the cloud server is semi-trusted, which possibly threaten the data's security. In addition, because the data owner will not physically possess the data after outsourcing the data to the cloud, it is required to check the storage correctness and data integrity. Cloud auditing protocols are proposed to solve this problem, but the efficiency and security of previous protocols are not well. In this paper, we proposed an enhanced auditing protocol, which can reduce the verification cost greatly and offer enough security assurance. Besides, our protocol is able to resist the forgery attack in the proof verification. The security and performance analysis shows that the proposed protocol can efficiently support storage verification and privacy preserving."
W,16,"With the rapid development of the economy and society, the sustainable development of resources and environment has been paid more and more attention. As an important part of the national environmental supervision system, resources and environmental audits have attracted great attention from the society. In order to explore the application effect of intelligent networking technology in resource and environment audit, this study carries out monitoring sampling, information collection, and later data processing optimization in resource and environment audit projects through the reference of artificial intelligence technology and method and combined with Internet of things big data analysis, which brings new Turks to the development of natural resource and environment audit and helps to improve the efficiency of audit work. Through the application of new technology in the sampling process of environmental information, the staff use new technology to collect, analyze, and mine data and explore how the new technology can promote the efficiency of resource and environmental audit and better promote the construction of ecological civilization."
W,17,"Data provenance is information about where data come from (provenance data) and how they transform (provenance transformation). Data provenance is widely used to evaluate data quality, trace errors, audit data, and understand references among data. Current studies on data provenance in relational database management systems (RDBMS) still have limitations in supporting full-featured SQL or procedural languages. With these challenges in mind, we present a formal definition of provenance data and provenance transformation for relational data. Then, we propose a solution to support data provenance in relational databases, including provenance graphs and provenance routes. Our method not only solves the complicated problem of modeling provenance in DBMS but also is capable of extending procedural languages in SQL. We also present ProvPg, a PostgreSQL-based prototype database system supporting data provenance in multiple granularities. ProvPg implements extraction, calculation, query, and visualization of provenance. We perform TPC-H tests for ProvPg and PostgreSQL, respectively. Experimental results show that ProvPg addresses the vision of supporting data provenance with little extra computation overhead for the execution engine, which indicates that our model is applicable to lineage tracing applications."
W,18,"Purpose This study conducts a systematic review using 452 academic and industry articles from an initial set of 60,899 records obtained by 3 databases from 2012 to 2020. The authors compare and contrast blockchains with existing legacy systems. The authors identify existing regulation, accounting standards, guidelines and potential amendments in under-explored areas such as taxation, accounting treatment of crypto-assets/liabilities and detailed auditing procedures. The study aims to highlight the trends, differences and gaps between academic and industry literature. The authors provide a behavioral, social, cultural, organizational, regulatory, ethical, accountability and managerial perspectives of blockchain adoption in accounting. Finally, the study develops two adoption frameworks. Design/methodology/approach The authors' study follows (Moher et al., 2009) and (Briner and Denyer, 2012) methodology to conduct the systematic review and the steps are mentioned below. The authors construct a final sample of 452 from a preliminary search of three multi-disciplinary databases from 2012 to 2020. First, the authors motivate the review and formulate the research questions. Second, the authors aggregate relevant literature from both industry and academia and implement quality assessments. Third, the authors analyze the literature and construct the final sample of articles. Fourth, the authors conducted textual analysis, keyword frequencies and identify gaps, trends and similarities between academic and industry literature and develop the authors' frameworks Findings The authors identify 3 (ABDC, B and A* ranked) journals as publishing top article numbers with the highest article count for 2017 with 96 articles in academia and 2019 for the industry with 21 articles. Second-highest publications for academia occur in 2018 with 77 followed by, whereas in the industry, publications occur in the year 2016 with 16 articles. Two co-authors appear most popular with 103 articles. Word clouds, a mind map and article theme counts are used to identify nine key research clusters: data management, financial applications, sustainability, accounting and auditing, business and industrial, education, governance, privacy/security and disruptive technology. Research limitations/implications Systematic reviews can have selection biases mainly due to search and selection criteria distortions when constructing the final sample of articles. The authors address selection bias by refining our search keyword combinations by using different permutations and using keywords from articles already collected. The authors employ three databases and review the reference list of articles collected to add more articles that may have been missed into our sample. In addition, to avoid inconsistent coding of domains/themes and interpretations, the authors carefully review our domain identifications and all our analysis twice independently using two research assistants to obtain the same conclusions. Practical implications The authors' unique contributions include reviewing additional papers, differentiating between industry, academic articles, common trends and gaps in much scattered prior literature. The authors identify existing accounting standards, guidelines, limitations and possible amendments required in future for blockchain adoption in accounting in taxation, accounting treatment of crypto-assets/liabilities and detailed audit procedures. Blockchains are compared with legacy accounting technologies and two frameworks for adoption developed. The authors' results could impact the understanding of existing regulation, accounting standards, future amendments, areas requiring clarity and future collaborative research between academia and industry across multi-disciplines. Practical implications to academics, professional bodies, regulators and industry practitioners exist. Social implications The authors' study identifies significant implications on organizations, environment, culture and society in general. The authors identify that social engagement projects may be easily initiated and implemented with decentralized accounting information systems. Transparency and efficiency would change organization culture, ways accountants and even employees interact with each other and community. Anonymity in blockchains can be used for criminal activities. Coding of negative social dynamics to smart contracts may persist. Transparency of personally identifiable information may place individuals at risk. Regulation and standards would need to identify equity, ethics in blockchains which notwithstanding energy consumption, and could enable environmental protection increasing societal sustainability. Originality/value To the authors' knowledge, this is the first study that compares academic and industry literature of 452 articles to identify gaps and similarities from 2012 to 2020 using three multi-disciplinary databases. The authors' study is the first study to in detail existing accounting standards, unclear areas, future amendments for International Financial Reporting Standards (IFRS) standards on taxation, financial reporting and all aspects of auditing procedures. The authors further categorize prior literature into these key areas and develop two frameworks (DAERPS and DAIS) that are linked to our review results and prior literature. The authors identify the impact of blockchain adoption on key stakeholders, regulation, society, culture, organization, accountability and ethics."
W,19,"Fragmentation of reformatting trends in corporate reporting, differentiation national approaches to the regulation of accounting systems and the lack of academic studies of accounting innovations cosed an urgent need to identify key innovations in the development of corporate reporting, analyze the feasibility of their use. The aim of the article. The aim of the article is structural analysis of modern innovations in preparing and presenting corporate reporting and researching the prospects of their application based on the theory of diffusion of innovations The results of the analysis. Innovation diffusion theory as in instrument of interdisciplinary analysis allows to describe key parameters in spreading of actual accounting, audit and corporate reporting innovations, for example: relative advantage, compatibility, complexity of innovation, trialability and observability. Located in the order of accounting cycle (accounting of different types of operations, reporting after the end of the period, and rendering an auditors opinion), discussed technological innovations give an idea about the prospects of modern system of corporate reporting. Big data, accounting for Environmental, Social and corporate Governance criteria, preparation and presentation of integrated reporting, real-time reporting, conducting continuous audit with computer assisted audit technologies (CAAT), Global General Accepted Accounting Principles (GGAAP) and development of XBRL are the typical technological innovations that accompany the transformation corporate reporting process based on a new paradigm. Conclusions and directions of further researches. Big data is not only the product of accounting and reporting in real time, but also the basis for the continuous audit of the real-time reporting with advanced analytical technologies CAAT. Taking into account ESG-criteria in the course of business, the implementation of responsible investment requires the development of appropriate indicators and its accounting measurement for the demonstration of progress in achieving sustainability and corporate social responsibility. This ESG-criteria and indicator (non-financial information), spreading real-time reporting lead to the emergence of integrated reporting. It causes changes in approaches to public audit and confirmation of this type of reporting with the CAAT, artificial intelligence systems. GGAAP development, improvement of methodology of integrated reporting standards and International Standards on Quality, Control, Auditing, Review Other Assurance and Related Services acts as a response to the need to restoring confidence in the reporting on globalized financial marketsand independent verification of its quality. XBRL as a technology innovation serving as connecting-link the one that helps transmit understandable reporting to all stakeholders, minimizing the time and costs for its processing and analysis through the taxonomy. The combination of considered innovation are grounded necessitates of construction of convergent model of accounting, reporting and auditing, which fully meets the information needs of stakeholders on globalized financial markets and with the spreading of sustainability concept."
W,20,"Waste management directly and indirectly contributes to all sustainable development goals. Hence, the modernisation of the current ineffective management system through Industry 4.0-compatible technologies is urgently needed. Inspired by the fourth industrial revaluation, this study explores the potential application of waste management 4.0 in a local government area in Perth, Western Australia. The study considers a systematic literature review as part of an exploratory investigation of the current applications and practices of Industry 4.0 in the waste industry. Moreover, the study develops and tests a machine learning model to identify and measure household waste contamination as a waste management 4.0 case study application. The study reveals that waste management 4.0 offers various opportunities and sustainability benefits in reducing costs, improving efficiency in the supply chain and material flow, and reducing as well as eliminating waste by achieving holistic circular economy goals. The significant barriers and challenges involve initial investments in developing and maintaining waste management 4.0 technology, platform and data acquisition. The proof-of-concept case study on the machine learning model detects selected waste with considerable precision (over 70% for selected items). The number and quality of the labelled data significantly influences the model's accuracy. The data on waste contamination are essential for local governments to explore household waste recycling practices besides developing effective waste education and communication methods. The study concludes that waste management 4.0 can be an effective tool for acquiring real-time data; however, overcoming the current limitations needs to be addressed before applying waste management 4.0 into practice."
W,21,"The whole world is facing the urgent issue of balancing economic development and ecological conservation. The fulfillment of the solution requires green innovation at the regional level. However, the heterogeneity of green innovation is obvious in different regions. To explore ways at effectively improving the level of regional green innovation in China, the research develops decomposition analysis based on the Logarithmic Mean Divisia Index (LMDI) model to identify the driving factors of green innovation. We also take the Geographical and Temporal Weighted Regression (GTWR) model to explore the driving factors of spatial-temporal heterogeneity of green innovation in China. The main results are as follows. Research and development (R&D) efficiency play a dominant role for increasing regional green patent applications, while environmental regulation contributes the most to a decline of regional green patent applications during 2003-2017. Various determinants of green patent applications exhibit spatial-temporal heterogeneity, such as the coefficients of influencing factors for each province in 2017 being more significant than the same coefficients in 2003. Beijing's coefficient of R&D efficiency is the largest, while the coefficient of economic development for Shanxi is the largest. The findings herein provide detailed insight for China's policymakers to effectively improve the level of regional green innovation domestically, which is of constructive significance to narrow the gap of regional green innovation and realize the coordinated and sustainable development of economy. (C) 2020 Elsevier Ltd. All rights reserved."
W,22,"Assuring future performance of systems-of-systems through advanced-technology investments is a perpetual challenge of industry and agencies. Among the complicating factors are technology innovation, escalating scales, and diversity of software and hardware applications, increasing availability and scrutiny of big data, and evolving business, environmental, and legal contexts. These factors are engaging system owner/operators to continually reprioritize these investments, even as transparent principles for investment are needed for appropriate oversight and auditing. In this paper, a branch of resilience analysis offers to address multiple layers of uncertainty that arise from technology plans around future disruptions to large-scale systems-of-systems. The paper presents a methodology to quantify and manage the disruptive influence of individual systems perspectives to the prioritization of technology investments across the system-of-systems. The methodology is demonstrated through a case study on an information technology investment portfolio of the US Department of Commerce, USA. The experience suggests how fiscal limitations, combining with several other factors, has the largest disruption to the prioritization of investments. The results furthermore describe how investments perform relative to one another and characterize where the system-of-systems might be resilient to the perspectives of constituent systems."
W,23,"Background Street imagery is a promising and growing big data source providing current and historical images in more than 100 countries. Studies have reported using this data to audit road infrastructure and other built environment features. Here we explore a novel application, using Google Street View (GSV) to predict travel patterns at the city level. Methods We sampled 34 cities in Great Britain. In each city, we accessed 2000 GSV images from 1000 random locations. We selected archived images from time periods overlapping with the 2011 Census and the 2011-2013 Active People Survey (APS). We manually annotated the images into seven categories of road users. We developed regression models with the counts of images of road users as predictors. The outcomes included Census-reported commute shares of four modes (combined walking plus public transport, cycling, motorcycle, and car), as well as APS-reported past-month participation in walking and cycling. Results We found high correlations between GSV counts of cyclists ('GSV-cyclists') and cycle commute mode share (r = 0.92)/past-month cycling (r = 0.90). Likewise, GSV-pedestrians was moderately correlated with past-month walking for transport (r = 0.46), GSV-motorcycles was moderately correlated with commute share of motorcycles (r = 0.44), and GSV-buses was highly correlated with commute share of walking plus public transport (r = 0.81). GSV-car was not correlated with car commute mode share (r = -0.12). However, in multivariable regression models, all outcomes were predicted well, except past-month walking. The prediction performance was measured using cross-validation analyses. GSV-buses and GSV-cyclists are the strongest predictors for most outcomes. Conclusions GSV images are a promising new big data source to predict urban mobility patterns. Predictive power was the greatest for those modes that varied the most (cycle and bus). With its ability to identify mode of travel and capture street activity often excluded in routinely carried out surveys, GSV has the potential to be complementary to new and traditional data. With half the world's population covered by street imagery, and with up to 10 years historical data available in GSV, further testing across multiple settings is warranted both for cross-sectional and longitudinal assessments."
W,24,"The widespread application of big data has had a profound impact on social and economic development. Government auditing is the guarantee for the modernization of national governance, and the development of big data audit capability has become the key to improving national governance capability. This paper summarizes the concept of government audit big data capability, and constructs the influencing factor model of government audit big data capability. This study finds that the construction degree of audit big data platform, big data management ability, big data audit technology and auditors' big data technology ability have a significant positive impact on the government audit big data ability, and the audit organization coordination ability plays a positive moderating effect in the whole impact process. This study provides guidance for the improvement and development of government audit big data capability."
W,25,"Poverty alleviation is a poverty alleviation model with Chinese characteristics. In the practice of the poverty alleviation model, the concept of poverty alleviation audit has been derived. With the continuous development of Internet information technology, the poverty alleviation audit method can no longer meet the needs of the development of modern society, and the construction of audit information is imperative. This paper adopts a research method combining theoretical analysis and practical application, and builds an intelligent system of rural poverty alleviation audit based on the method of big data anomaly detection. Various steps in the big data audit work are analyzed, including the storage and sharing of data, and the determination of data collection standards."
W,26,"Cloud computing opens a new era in IT as it can provide various elastic and scalable IT services in a pay-as-you-go fashion, where its users can reduce the huge capital investments in their own IT infrastructure. In this philosophy, users of cloud storage services no longer physically maintain direct control over their data, which makes data security one of the major concerns of using cloud. Existing research work already allows data integrity to be verified without possession of the actual data file. When the verification is done by a trusted third party, this verification process is also called data auditing, and this third party is called an auditor. However, such schemes in existence suffer from several common drawbacks. First, a necessary authorization/authentication process is missing between the auditor and cloud service provider, i.e., anyone can challenge the cloud service provider for a proof of integrity of certain file, which potentially puts the quality of the so-called 'auditing-as-a-service' at risk; Second, although some of the recent work based on BLS signature can already support fully dynamic data updates over fixed-size data blocks, they only support updates with fixed-sized blocks as basic unit, which we call coarse-grained updates. As a result, every small update will cause re-computation and updating of the authenticator for an entire file block, which in turn causes higher storage and communication overheads. In this paper, we provide a formal analysis for possible types of fine-grained data updates and propose a scheme that can fully support authorized auditing and fine-grained update requests. Based on our scheme, we also propose an enhancement that can dramatically reduce communication overheads for verifying small updates. Theoretical analysis and experimental results demonstrate that our scheme can offer not only enhanced security and flexibility, but also significantly lower overhead for big data applications with a large number of frequent small updates, such as applications in social media and business transactions."
W,27,"The purpose is to further explore the application effect of the neural network algorithm in defense audit and improve the user information security performance. Based on the relevant theoretical basis of neural network in machine learning, the back propagation neural network (BPNN) algorithm model is constructed and optimized. Moreover, by comparing with the classification and prediction effect of the decision tree method, the application effect of BPNN is further clarified. Through statistical analysis, a total of six risk users are screened out. The test data are classified into non-risk user group and risk user group to study the prediction of classification. The specific results are as follows. The prediction accuracy of non-risk group is 99% by using the BPNN algorithm and that is improved to 99.5% by using the optimized BPNN; for risk group, the prediction accuracy of BPNN is only 50% and that of optimized BPNN is 83.3%. Meanwhile, the prediction error rate of the BPNN algorithm is significantly lower than that of the decision tree algorithm, which further verifies the good application effect of the BPNN algorithm. This study can provide scientific and effective reference for the follow-up research of defense audit."
W,28,"Database auditing is one of the biggest issues in data security. Absence of information auditing drives the business applications to the lost trail of business procedures. To cope with auditing and in order to track operations and the actors of those operations in time, we need historical data or temporary database. Legitimate and exchange times are two important time-stamps in temporary database. In this paper, we show the methods to handle database auditing in business exchange operations, accurate times, and performers of the operations. These strategies are separated in two sets; utilizing relational databases, and utilizing semi-structured information."
W,29,"BackgroundBig Data analytics such as credit scoring and predictive analytics offer numerous opportunities but also raise considerable concerns, among which the most pressing is the risk of discrimination. Although this issue has been examined before, a comprehensive study on this topic is still lacking. This literature review aims to identify studies on Big Data in relation to discrimination in order to (1) understand the causes and consequences of discrimination in data mining, (2) identify barriers to fair data-mining and (3) explore potential solutions to this problem.MethodsSix databases were systematically searched (between 2010 and 2017): PsychINDEX, SocIndex, PhilPapers, Cinhal, Pubmed and Web of Science.ResultsMost of the articles addressed the potential risk of discrimination of data mining technologies in numerous aspects of daily life (e.g. employment, marketing, credit scoring). The majority of the papers focused on instances of discrimination related to historically vulnerable categories, while others expressed the concern that scoring systems and predictive analytics might introduce new forms of discrimination in sectors like insurance and healthcare. Discriminatory consequences of data mining were mainly attributed to human bias and shortcomings of the law; therefore suggested solutions included comprehensive auditing strategies, implementation of data protection legislation and transparency enhancing strategies. Some publications also highlighted positive applications of Big Data technologies.ConclusionThis systematic review primarily highlights the need for additional empirical research to assess how discriminatory practices are both voluntarily and accidentally emerging from the increasing use of data analytics in our daily life. Moreover, since the majority of papers focused on the negative discriminative consequences of Big Data, more research is needed on the potential positive uses of Big Data with regards to social disparity."
W,30,"The practices of Big Data policing platform indicated that big data technology will play an important role for national crime prevention, detection and the fight against terrorism. How to balance the public's privacy is a big problem in the process of establishing Policing platform based on big data. Domain Awareness System is an Inspectorate crime prevention and anti-terrorism technology based on Big Data in New York City Police Department. The successful system can't be inseparable from its public security privacy guidelines. The guidelines also can give some suggestion for big data policing in China. We suggested a series of rules including legal restriction of the police application for big data, privacy protection rules to different data types, strengthen information security technology, strict regulatory system and data usage audit."
W,31,"With the emergence of cloud storage providers (CSP), an increasing number of users tend to migrate their data to the cloud, but users lose direct control over the data. To ensure data security in the cloud, it is necessary to introduce a third-party auditor (TPA) to audit the integrity of cloud data, but the TPA is not fully trusted. Therefore, our approach proposes a blockchain-based integrity auditing method. First, we construct a new integrity audit tree, which can be used to quickly generate the verification tag. Second, we use blockchain to store the audit records of the TPA so that the audit process can be checked at any time. Finally, we design a verification algorithm for audit results that can identify dishonest behavior of the TPA and the CSP. Theoretical analysis shows that our scheme can detect the behavior of TPA delaying audits, falsifying audit results and colluding with the CSP. Moreover, simulation experiments show that our scheme outperforms existing blockchain-based auditing schemes in terms of time overhead."
W,32,"As a very popular application of cloud computing, CLOUD storage allows the users to outsource their data file to the cloud in order to share their data files. However, cloud storage server is an untrusted entity, it might neglect to keep or even deliberately remove the shared data which are rarely accessed. To ensure the integrity of their shared data in cloud, a number of data sharing auditing schemes have been proposed. However, these scheme only can achieve that multiple users edit the whole shared data, not realize that the specified user edits the specified portion of the shared data. In some cases, we need the specified user to revise the specified portion of the data file, such as EHR system. To achieve such function, in this paper we propose a novel public auditing scheme for the dynamic data sharing. It can achieve the specified data users edit the specific part of the shared data file. To the best of our knowledge, it is the first scheme which satisfies such function. Furthermore, the outstanding highlight of the scheme is that the auditor has constant communication cost and computational cost. By the detailed simulation and comparisons with the state-of-the-art scheme, The results demonstrate that the proposed scheme our scheme has many advantages in terms of data block updating, user revocation and integrity verification time. Finally, we formally prove the security of the proposed scheme, and evaluate the auditing performance."
W,33,"Big data itself and big data technology are affecting the development of society, and thus affect the economic research. In order to fully understand the research hotspots and development trends of big data in the field of Chinese economics, this article shows the overview of the big data researches based on the Chinese Social Science Citation Index (CSSCI), with the software CitespaceV, which takes big data as the key word, and economics as the literature category. The progresses of big data researches in the field of economics are reviewed, and the existing literatures from three aspects, namely research hotspots, evolution of research hotspots and research basic knowledge are compared and analyzed. This research shows that: 1) The hotspots of the researches are big data, internet finance, cloud computing, data mining, smart cities, precision poverty alleviation, etc.; 2) Big data appears in the Internet of Things clustering at first and gradually evolves to online shopping, internet finance, and classified networks clustering; 3) The high-cited literatures on big data have gone through the stages from theory to application, and applications have focused on taxation and auditing."
W,34,"Big data drive multidimensional convergence and profound innovations among industries and provide novel ways of exploring the world. As they significantly create economic and social value, big data meaningfully impact the implementation and management of information security and privacy protection. Cryptographic technologies are used to protect the security and entire life cycle of big data. The demand for this technology is multiplied when the data are stored in the cloud. They are stored in the cloud in the form of ciphertext, and the driving requirement for data retrieval, sharing, and manipulation places the security of data at risk. The all-or-nothing approach of traditional cryptography systems cannot realize the release and processing of data information with flexible and increasingly fine granularity. Consequently, dealing with the relationship between privacy protection and data utilization, as well as navigating the blurry boundaries between subverting either plaintext or ciphertext, has become a research focus of the current cryptographic trend for protecting big data security. Presently, there are many studies designed to solve these limitations. First, security requirements and source encryption mode for future big data systems and applications are elaborated. Then, focusing on the practical security and functionality of the big data life cycle, including storage, retrieval, sharing, calculation, statistical analysis, and utilization, the research being conducted based on those functions is reviewed. For each cryptographic technology that meets the requirement of each type of big data security or application, security and efficiency comments and sufficient comparison analyses of cryptography schemes or protocols are provided; moreover, the current general problems and development trends are expounded. Because the current innovative research on cryptographic technology was primarily based on the development or improvement of a single solution, the study on the security of the entire big data life cycle from a holistic perspective is extremely limited. Finally, based on surveys and integration of cryptographic techniques, a compatible and comprehensive reference cryptographic architecture for big data security (Z-CABDS) is proposed, which can be used to guide each sub-direction to cooperate with each other to achieve the full life cycle security of big data. Moreover, certain challenges, open problems, and thoughts on future research related to the cryptography of big data security from the viewpoint of the entire big data life cycle are addressed, including views on information theory, the intersection and fusion of technologies, and new technology derivation, which aims to provide a good reference and inspiration for follow-up research."
W,35,"With the increasing demand for ubiquitous connectivity, wireless technology has significantly improved our daily lives. Meanwhile, together with cloud-computing technology (e.g., cloud storage services and big data processing), new wireless networking technology becomes the foundation infrastructure of emerging communication networks. Particularly, cloud storage has been widely used in services, such as data outsourcing and resource sharing, among the heterogeneous wireless environments because of its convenience, low cost, and flexibility. However, users/clients lose the physical control of their data after outsourcing. Consequently, ensuring the integrity of the outsourced data becomes an important security requirement of cloud storage applications. In this paper, we present Co-Check, a collaborative multicloud data integrity audition scheme, which is based on BLS (Boneh-Lynn-Shacham) signature and homomorphic tags. According to the proposed scheme, clients can audit their outsourced data in a one-round challenge-response interaction with low performance overhead. Our scheme also supports dynamic data maintenance. The theoretical analysis and experiment results illustrate that our scheme is provably secure and efficient."
W,36,"Purpose The purpose of this study is to map the conceptual structure of the body of knowledge linking digital technologies and auditing, with the aim of contributing to a better understanding of this research stream. Design/methodology/approach This research develops a bibliometric analysis of 256 articles following two steps. The analysis of descriptive performance indicators identifies the main traits of the community of scholars debating audit and technology in terms of publications, productive countries and authors, as well as the publication's impact of the target journals concerning specific fields, number of citations per country and most cited articles in the data set. To analyse the conceptual structure of the data set, the study performs a co-word analysis adopting social network analysis tools. Findings The results highlight a growing academic interest in the research topic, especially in the past few years. The bibliometric analysis reveals three main topics concerning the use and application of technology in the audit profession: the adoption of continuous auditing and continuous monitoring in the auditing profession; the use of software tools in the audit profession; the connections between information systems and audit. Originality/value This paper contributes to the field by providing an examination of the current state of the art of research on the use and application of technology in the audit profession as well as identifying the current gaps in the literature and, most importantly, propose a research agenda for the field."
W,37,"Purpose - Information technology (IT) largely affected contemporary businesses, and accordingly, it imposes challenges on the auditing profession. Several studies investigated the impact of IT, in terms of the extent of use of IT audit techniques, but very studies are available on the perceived importance of the said issue in developing countries. This study aims to explore the impact of implementing IT on the auditing profession in a developing country, namely, Egypt. Design/methodology/approach - This study uses both quantitative and qualitative data. A survey of 112 auditors, representing three of the Big 4 audit firms as well as ten local audit firms in Egypt, is used to gather preliminary data, and semi-structured interviews are conducted to gather details/qualitative-pertained information. A field-based questionnaire developed by Bierstaker and Lowe (2008) is used in this study. This questionnaire is used first in conducting a pre-test, and then, the questionnaire for testing the final results is developed based on the feedback received from the test sample. Findings - The findings of this study reveal that auditors' perception regarding client's IT complexity is significantly affected by the use of IT specialists and the IT expertise of the auditors. Besides, they perceive that the new audit applications' importance and the extent of their usage are significantly affected by the IT expertise of the auditors. The results also reveal that the auditors' perception regarding the client's IT is not affected by the control risk assessment. However, the auditors perceive that the client's IT is significantly affected by electronic data retention policies. The results also indicated that the auditors' perception regarding the importance of the new audit applications is not affected by the client's type of industry. The auditors find that the uses of audit applications as well as their IT expertise are not significantly affected by the audit firm size. However, they perceive that the client's IT complexity as well as the extent of using IT specialists are significantly affected by the audit firm size. Research limitations/implications - This study is subject to certain limitations. First, the sample size of this research is somehow small because it is based on the convenience sampling technique, and some of the respondents were not helpful in answering the surveys distributed for this research's purpose. This can be attributed to the fear of the competitors that their opponent may want to gather information regarding their work to be able to succeed in the competition in the market so they become reluctant to provide any information about their firm. Even some people who were interested to participate were not having enough time because the surveys were distributed during the high season of their audit work and there was limited time for the research to be accomplished. Hence, it is difficult to generalize the results among all the audit firms in Egypt because this limits the scope of the analysis, and it can be a significant obstacle in finding a trend. However, this can be an opportunity for future research. Second, the questionnaire is long and people do not have enough time to complete it. This also affected the response rate. In addition to this, the language of the questionnaire was English, so some respondents from the local audit firms were finding difficulty in understanding some sophisticated IT terms. Practical implications - This study makes some recommends/suggestions that can well be used to solve some practical problems regarding the issues concerned. This study focuses on accounting information system (AIS) training during the initial years of the auditors' careers to help staff auditors when they become seniors to be more skilled with AIS expertise needed in today's audit environment. Clear policy statements are important to direct employees so that IT auditors evaluate the adequacy of standards and comply with them. This study suggests increasing the use of AIS to enhance individual technical and analytical skill sets and to develop specialized teams capable of evaluating the effectiveness of computer systems during audit engagements. This study further recommends establishing Egyptian auditing standards in this electronic environment to guide the auditors while conducting their audit work. Social implications - Auditors should prioritize causes of risks and manage them with clear understanding of who receives them, how they are communicated and what action should be taken in a given community/society. So, they have to determine and evaluate all risks according to the client's type of industry (manufacturing, non- financial services and financial). Auditors also have to continually receive feedback on the utility of continuous auditing (CA) in assessing risk. In particular, it is better for the auditor to determine how the audit results will be used in the enterprise risk management activity performed by the management. In addition, privacy has several implications to auditing, and so, it has to be reflected in the audit program and planning as well as the handling of assignment files and reports. Alike, retention of electronic evidence for a limited period of time may require the auditor to select samples several times during the audit period rather than just at year end. Originality/value - As mentioned, this study is conducted within a developing country's context. The use and importance of IT is reality of time. However, very few studies are devoted to explore the use/importance of IT in auditing in developing countries, and thus, this study carries a significance to have better understanding about it. Moreover, knowledge of how IT is used, the related risks and the ability to use IT as a resource in the performance of audit work is essential for auditor effectiveness at all levels including developing countries."
W,38,"In today's big-data era, enterprises are able to generate complex and non-structured information that could cause considerable challenges for CPA firms in data analysis and to issue improper audited reports within the required period. Artificial intelligence (AI)-enabled auditing technology not only facilitates accurate and comprehensive auditing for CPA firms, but is also a major breakthrough in auditing's new environment. Applications of an AI-enabled auditing technique in external auditing can add to auditing efficiency, increase financial reporting accountability, ensure audit quality, and assist decision-makers in making reliable decisions. Strategies related to the adoption of an AI-enabled auditing technique by CPA firms cover the classical multiple criteria decision-making (MCDM) task (i.e., several perspectives/criteria must be considered). To address this critical task, the present study proposes a fusion multiple rule-based decision making (MRDM) model that integrates rule-based technique (i.e., the fuzzy rough set theory (FRST) with ant colony optimization (ACO)) into MCDM techniques that can assist decision makers in selecting the best methods necessary to achieve the aspired goals of audit success. We also consider potential implications for articulating suitable strategies that can improve the adoption of AI-enabled auditing techniques and that target continuous improvement and sustainable development."
W,39,"Purpose This study aims to provide an empirically informed view on the auditing profession's readiness to embrace disruptive technologies. Relying on evidence from Big 4 employees in Italy, this study examines the factors that motivate auditors to use blockchain technology (BT). Design/methodology/approach To this aim, this study uses an integrated theoretical frame merging the third version of the technology acceptance model (TAM3) and the unified theory of acceptance and use of technology (UTAUT). The analytical model is based on an application of the structural equation modelling with partial least square estimation on data gathered through a Likert-based questionnaire. Findings The findings reveal that the main predictors of auditors' intention to use blockchain are performance expectancy and social influence. Moreover, auditors' effort expectancy in relation to this technology implementation and use appears to be a reasonably reliable predictor. Originality/value This paper contributes an evidence-based view to the discussion on the impact of automation and disruptive information and communication technologies, on the roles of accounting and auditing professionals. It uses a novel approach to analysis by integrating TAM3 and UTAUT within its theoretical model. It complements and extends the field of studies on technology acceptance by offering fresh insights into auditors' perceptions. Finally, the paper highlights practical implications for business leaders aiming to use the advantages of BT in audit firms."
W,40,"Financial reporting and assurance in their current form are losing relevance to investors in firm valuations. New sources of data, especially exogenous or external data that are generated outside the organizations, have opened doors to new ways of business measurement and information validation. Examples of exogenous data include social media, online searches, social networks, and news media. This paper discusses the state-of-the-art applications of exogenous data in the measurement and assurance of business reporting, ESG, and cybersecurity and provides potential avenues for future research. Furthermore, this paper speculates on the nature of the new paradigm of business measurement and assurance with exogenous data and the difficulties that are emerging."
W,41,"Gender inequality has exploded as a recent issue within mainstream media across US and UK cultural commentary. High-profile scandals of sexual harassment and gender pay differences have focused attention on the on-going disparity between sexes and political status. This paper presents a novel experiment in the application of so-called big data to analyse gender inequality. Using Artificial Intelligence (AI) techniques in the form of Natural Language Processing, a web crawler is used to audit the whole.uk online domain, and to measure the United Kingdom's (UK's) online economic presence for gender representation in terms of: prominence, job roles, and leadership within and across economic sectors. The procedure scans over 200 million web pages, and harvests 157,032 organisations and over 2.3 million people. The results reveal material bias (60%+) towards the representation of men over the majority of economic sectors, and across representation of power and status within job roles and professional titles. The experiment highlights not only new levels of gender bias but also the use of the Internet as a valuable source of plentiful data for social and economic analysis."
W,42,"Purpose This study conducts a systematic review using 452 academic and industry articles from an initial set of 60,899 records obtained by 3 databases from 2012 to 2020. The authors compare and contrast blockchains with existing legacy systems. The authors identify existing regulation, accounting standards, guidelines and potential amendments in under-explored areas such as taxation, accounting treatment of crypto-assets/liabilities and detailed auditing procedures. The study aims to highlight the trends, differences and gaps between academic and industry literature. The authors provide a behavioral, social, cultural, organizational, regulatory, ethical, accountability and managerial perspectives of blockchain adoption in accounting. Finally, the study develops two adoption frameworks. Design/methodology/approach The authors' study follows (Moher et al., 2009) and (Briner and Denyer, 2012) methodology to conduct the systematic review and the steps are mentioned below. The authors construct a final sample of 452 from a preliminary search of three multi-disciplinary databases from 2012 to 2020. First, the authors motivate the review and formulate the research questions. Second, the authors aggregate relevant literature from both industry and academia and implement quality assessments. Third, the authors analyze the literature and construct the final sample of articles. Fourth, the authors conducted textual analysis, keyword frequencies and identify gaps, trends and similarities between academic and industry literature and develop the authors' frameworks Findings The authors identify 3 (ABDC, B and A* ranked) journals as publishing top article numbers with the highest article count for 2017 with 96 articles in academia and 2019 for the industry with 21 articles. Second-highest publications for academia occur in 2018 with 77 followed by, whereas in the industry, publications occur in the year 2016 with 16 articles. Two co-authors appear most popular with 103 articles. Word clouds, a mind map and article theme counts are used to identify nine key research clusters: data management, financial applications, sustainability, accounting and auditing, business and industrial, education, governance, privacy/security and disruptive technology. Research limitations/implications Systematic reviews can have selection biases mainly due to search and selection criteria distortions when constructing the final sample of articles. The authors address selection bias by refining our search keyword combinations by using different permutations and using keywords from articles already collected. The authors employ three databases and review the reference list of articles collected to add more articles that may have been missed into our sample. In addition, to avoid inconsistent coding of domains/themes and interpretations, the authors carefully review our domain identifications and all our analysis twice independently using two research assistants to obtain the same conclusions. Practical implications The authors' unique contributions include reviewing additional papers, differentiating between industry, academic articles, common trends and gaps in much scattered prior literature. The authors identify existing accounting standards, guidelines, limitations and possible amendments required in future for blockchain adoption in accounting in taxation, accounting treatment of crypto-assets/liabilities and detailed audit procedures. Blockchains are compared with legacy accounting technologies and two frameworks for adoption developed. The authors' results could impact the understanding of existing regulation, accounting standards, future amendments, areas requiring clarity and future collaborative research between academia and industry across multi-disciplines. Practical implications to academics, professional bodies, regulators and industry practitioners exist. Social implications The authors' study identifies significant implications on organizations, environment, culture and society in general. The authors identify that social engagement projects may be easily initiated and implemented with decentralized accounting information systems. Transparency and efficiency would change organization culture, ways accountants and even employees interact with each other and community. Anonymity in blockchains can be used for criminal activities. Coding of negative social dynamics to smart contracts may persist. Transparency of personally identifiable information may place individuals at risk. Regulation and standards would need to identify equity, ethics in blockchains which notwithstanding energy consumption, and could enable environmental protection increasing societal sustainability. Originality/value To the authors' knowledge, this is the first study that compares academic and industry literature of 452 articles to identify gaps and similarities from 2012 to 2020 using three multi-disciplinary databases. The authors' study is the first study to in detail existing accounting standards, unclear areas, future amendments for International Financial Reporting Standards (IFRS) standards on taxation, financial reporting and all aspects of auditing procedures. The authors further categorize prior literature into these key areas and develop two frameworks (DAERPS and DAIS) that are linked to our review results and prior literature. The authors identify the impact of blockchain adoption on key stakeholders, regulation, society, culture, organization, accountability and ethics."
W,43,"Sharing data assets has emerged among organizations with variable interest, especially in the manner of federation. Blockchain has been used in data sharing systems to provide the audit and access control on data because of its tamper-proof characteristics. However, the user's authority is difficult to accurately describe because of the complexity of users' multidimensional roles in the federation. And when developing the decentralized access control mechanism with the support of blockchain techniques, how to improve the efficiency of the decision for access control is the problem that is necessary to be solved. In this paper, we propose a blockchain-based multidimensional user authorization and role-based access control mechanism in the federated data sharing system. The colored coin is defined to identify the user's authority in multi-dimension, and decentralized access control decision is achieved through the automatic execution of smart contracts, thereby effectively enhancing the mechanism robustness and improving the security decision performance. The system is implemented on the basis of HyperLedger Fabric. Experimental results show that the proposed scheme is feasible and efficient. The decision efficiency is remained stable with the increasing of policy rules."
W,44,"This article offers a detailed examination of the content of predictive policing applications. Crime prediction machines are used by governments to shape the moral behavior of police. They serve not only to predict when and where crime is likely to occur, but also to regulate police work. They calculate equivalence ratios, distributing security across the territory based on multiple cost and social justice criteria. Tracing the origins of predictive policing in the Compstat system, this article studies the shift from machines to explore intuitions (where police officers still have control over the machine) to applications removing the reflexive dimension of proactivity, thus turning prediction into the medium for dosage metrics of police work quantities. Finally, the article discusses how, driven by a critical movement denouncing the discriminatory biases of predictive machines, developers seek to develop techniques to audit training dataset and ways to calculate the reasonable amount of stop and frisk over the population."
W,45,"This research pulls together the increasing need for specialist numerate data professionals in the contemporary workforce with an appreciation that these skills need to be embedded far earlier in the student education lifecycle. With 90 per cent of the world's data generated in the past two years, the data needs of industry are changing. Core quantitative skills such as descriptive statistics and probability are still important but are being overtaken by the technical skills needed to handle 'Big Data' and other new forms of data. This research undertakes a skills audit of industry before developing pedagogically-influenced Massive Open Online Courses (MOOCs) aimed at pupils and teachers at the GCSE and A-Level stage of education in the United Kingdom. The interactive courses, which will be made available via the FutureLearn educational platform, will enable pupils to see first-hand how data can be used to solve problems in a wide range of application areas such as crime, health and business whilst at the same time introducing new data forms such as 'Big Data' and social media. The resources will be designed in a way such that they can be used by teachers for whole-class sessions or taken by interested pupils in their own time to develop their skills and interests and enhance university applications. All resources will be fully supported and endorsed by Q-Step, a national initiative that seeks to get more students using and embracing data. Whilst this research is about enhancing data and quantitative skills, it is not directed by probability and descriptive statistics - topics which have been part of quantitative curricula for many years. It is about using engaging examples and interactive forms of teaching to introduce twenty-first century data skills to young people at a time when their academic interests are first developing. This presentation will provide an update on this twelve-month project, ending December 2017."
W,46,"As the globally increasing population drives rapid urbanization in various parts of the world, there is a great need to deliberate on the future of the cities worth living. In particular, as modern smart cities embrace more and more data-driven artificial intelligence services, it is worth remembering that (1) technology can facilitate prosperity, wellbeing, urban livability, or social justice, but only when it has the right analog complements (such as well-thought out policies, mature institutions, responsible governance); and (2) the ultimate objective of these smart cities is to facilitate and enhance human welfare and social flourishing. Researchers have shown that various technological business models and features can in fact contribute to social problems such as extremism, polarization, misinformation, and Internet addiction. In the light of these observations, addressing the philosophical and ethical questions involved in ensuring the security, safety, and interpretability of such AI algorithms that will form the technological bedrock of future cities assumes paramount importance. Globally there are calls for technology to be made more humane and human-centered. In this paper, we analyze and explore key challenges including security, robustness, interpretability, and ethical (data and algorithmic) challenges to a successful deployment of AI in human-centric applications, with a particular emphasis on the convergence of these concepts/challenges. We provide a detailed review of existing literature on these key challenges and analyze how one of these challenges may lead to others or help in solving other challenges. The paper also advises on the current limitations, pitfalls, and future directions of research in these domains, and how it can fill the current gaps and lead to better solutions. We believe such rigorous analysis will provide a baseline for future research in the domain. (C) 2021 Elsevier Inc. All rights reserved."
W,47,"Automatic constraint discovery from a relational database is beneficial for domain experts in fraud detection and intelligent auditing. Its objective is to discover a set of inherent constraints underlying the database such that tuples violating them are considered anomalous. In this paper, we propose IceBerg as the first system to simultaneously detect anomalous tuples and discover the associated human-readable constraints. The backbone of IceBerg is a novel generative network, namely KD-VAE, that integrates Kernel Density estimation with Variational AutoEncoder. KD-VAE is expected to learn the distributions of normal tuples. We can perform anomalous data detection by calculating the likelihood that the tuple fits the distributions of normal tuples and abnormality interpretation by comparing the detected anomalous tuples with their generated normal counterparts.We empirically compare the proposed method with several state-of-the-art outlier detection methods on 13 real-world datasets. The results show that IceBerg outperforms its competitors in most cases, especially for complex datasets with high-dimensional features."
W,48,"The pervasive application of algorithmic decision-making is raising concerns on the risk of unintended bias in AI systems deployed in critical settings such as healthcare. The detection and mitigation of model bias is a very delicate task that should be tackled with care and involving domain experts in the loop. In this paper we introduce FairLens, a methodology for discovering and explaining biases. We show how this tool can audit a fictional commercial black-box model acting as a clinical decision support system (DSS). In this scenario, the healthcare facility experts can use FairLens on their historical data to discover the biases of the model before incorporating it into the clinical decision flow. FairLens first stratifies the available patient data according to demographic attributes such as age, ethnicity, gender and healthcare insurance; it then assesses the model performance on such groups highlighting the most common misclassifications. Finally, FairLens allows the expert to examine one misclassification of interest by explaining which elements of the affected patients' clinical history drive the model error in the problematic group. We validate FairLens' ability to highlight bias in multilabel clinical DSSs introducing a multilabel-appropriate metric of disparity and proving its efficacy against other standard metrics."
W,49,"Fragmentation of reformatting trends in corporate reporting, differentiation national approaches to the regulation of accounting systems and the lack of academic studies of accounting innovations cosed an urgent need to identify key innovations in the development of corporate reporting, analyze the feasibility of their use. The aim of the article. The aim of the article is structural analysis of modern innovations in preparing and presenting corporate reporting and researching the prospects of their application based on the theory of diffusion of innovations The results of the analysis. Innovation diffusion theory as in instrument of interdisciplinary analysis allows to describe key parameters in spreading of actual accounting, audit and corporate reporting innovations, for example: relative advantage, compatibility, complexity of innovation, trialability and observability. Located in the order of accounting cycle (accounting of different types of operations, reporting after the end of the period, and rendering an auditors opinion), discussed technological innovations give an idea about the prospects of modern system of corporate reporting. Big data, accounting for Environmental, Social and corporate Governance criteria, preparation and presentation of integrated reporting, real-time reporting, conducting continuous audit with computer assisted audit technologies (CAAT), Global General Accepted Accounting Principles (GGAAP) and development of XBRL are the typical technological innovations that accompany the transformation corporate reporting process based on a new paradigm. Conclusions and directions of further researches. Big data is not only the product of accounting and reporting in real time, but also the basis for the continuous audit of the real-time reporting with advanced analytical technologies CAAT. Taking into account ESG-criteria in the course of business, the implementation of responsible investment requires the development of appropriate indicators and its accounting measurement for the demonstration of progress in achieving sustainability and corporate social responsibility. This ESG-criteria and indicator (non-financial information), spreading real-time reporting lead to the emergence of integrated reporting. It causes changes in approaches to public audit and confirmation of this type of reporting with the CAAT, artificial intelligence systems. GGAAP development, improvement of methodology of integrated reporting standards and International Standards on Quality, Control, Auditing, Review Other Assurance and Related Services acts as a response to the need to restoring confidence in the reporting on globalized financial marketsand independent verification of its quality. XBRL as a technology innovation serving as connecting-link the one that helps transmit understandable reporting to all stakeholders, minimizing the time and costs for its processing and analysis through the taxonomy. The combination of considered innovation are grounded necessitates of construction of convergent model of accounting, reporting and auditing, which fully meets the information needs of stakeholders on globalized financial markets and with the spreading of sustainability concept."
W,50,"Dynamic analysis of Android apps is often used together with an exerciser to increase its code coverage. One big obstacle in designing such Android app exercisers comes from the existence of text-based inputs, which are often constrained by the nature of the input field, such as the length and character restrictions. In this paper, we propose TextExerciser, an iterative, feedback-driven text input exerciser, which generates text inputs for Android apps. Our key insight is that Android apps often provide feedback, called hints, for malformed inputs so that our system can utilize such hints to improve the input generation. We implemented a prototype of TextExerciser and evaluated it by comparing TextExerciser with state-of-the-art exercisers, such as The Monkey and DroidBot. Our evaluation shows that TextExerciser can achieve significantly higher code coverage and trigger more sensitive behaviors than these tools. We also combine TextExerciser with dynamic analysis tools and show they are able to detect more privacy leaks and vulnerabilities with TextExerciser than with existing exercisers. Particularly, existing tools, under the help of TextExerciser, find several new vulnerabilities, such as one user credential leak in a popular social app with more than 10,000,000 downloads."
W,51,"Purpose - The purpose of this paper is to assess the practice of income smoothing in the Gulf Cooperation Council (GCC) emerging markets; Saudi Arabia, Kuwait, United Arab Emirates, Oman and Qatar. Then, to examine the impact of income smoothing on the earnings quality to decide whether income smoothing can serve as either a tool to enhance earnings quality or a tool for opportunistic behavior. Audit quality and corporate governance as additional factors are considered in this study. Design/methodology/approach - The study methodology measures income smoothing behavior based on the coefficient of variation method. Earnings quality is measured as an outcome of the explained variations in stock returns by earnings based on the efficient market hypothesis. Audit quality is measured based on brand as higher quality assigned to auditor from any of the Big 4, while the corporate governance is addressed based on the extent of governmental ownership. The initial study sample comprises 55 companies over a ten year period, from 1999 to 2008; the final sample represents approximately 64 percent of the industrial sector that have public data during the study. Findings - The results suggest that income smoothing behavior in the GCC markets has many variations in practice. Income smoothing, on average, improves earnings quality in three countries out of four, but not significantly for the whole sample based on earnings level. The earnings changes model demonstrated a positive and significant impact of income smoothing on earnings quality. Audit quality and earnings quality have a positive relationship within the region, and companies dominated by the government perform well in accordance with the earnings-return model. Research limitations/implications - The study is limited to the industrial sector of the GCC. Practical implications - The study opens the door to future applications to other sectors within the GCC, same sectors and other sectors for Middle East countries and other emerging markets. Social implications - The study may foster a better understanding of accounting practices in the GCC and Middle East. The study reveals variations in different aspects among GCC countries, this matter should be considered in separate studies across different areas. Originality/value - The study makes an original contribution to being the first to explore this topic in the GCC. Additionally, this study shows that the GCC markets have different characteristics in the practice and impact of income smoothing on earnings' quality. Further, audit quality and corporate governance was investigated for each country and for the region, in addition to the interaction between these factors with the income smoothing and earnings quality."
W,52,"Black box AI systems for automated decision making, often based on machine learning over (big) data, map a user's features into a class or a score without exposing the reasons why. This is problematic not only for lack of transparency, but also for possible biases inherited by the algorithms from human prejudices and collection artifacts hidden in the training data, which may lead to unfair or wrong decisions. We focus on the urgent open challenge of how to construct meaningful explanations of opaque AI/ML systems, introducing the local-toglobal framework for black box explanation, articulated along three lines: (i) the language for expressing explanations in terms of logic rules, with statistical and causal interpretation; (ii) the inference of local explanations for revealing the decision rationale for a specific case, by auditing the black box in the vicinity of the target instance; (iii), the bottom-up generalization of many local explanations into simple global ones, with algorithms that optimize for quality and comprehensibility. We argue that the local-first approach opens the door to a wide variety of alternative solutions along different dimensions: a variety of data sources (relational, text, images, etc.), a variety of learning problems (multi-label classification, regression, scoring, ranking), a variety of languages for expressing meaningful explanations, a variety of means to audit a black box."
W,53,"Social networks, smartphones, mobile applications... produce an avalanche of data on a large-scale and in an unstructured way. The phenomenon Big Data was born in order to address the different challenges including data storing, data analysis, data querying and so on. Technological advances always carry new security vulnerabilities that are not taken into consideration at the beginning. Security aspects usually require time to be addressed. The information system security is the set of measures to prevent any failure or threat including unauthorized accesses. Perfect protection must contain the four basic building blocks that are: authentication, access control, auditing, and encryption. In our work, we are specifically interested in access control. We first analyze the well-known access control models that were applied to Big Data. We then investigate the most important security projects. Most of these approaches and projects rely mainly on coarse-grained access control policies. In this work, we propose a novel approach called H-RCBAC that relies on two known models: the role-based access control (RBAC) and the content-based access control (CBAC). H-RCBAC is a new architecture that refines the access control process by considering a set of taboo words to guarantee fine-grained access control."
W,54,"Large-scale P2P applications (e.g., social networking, online gaming, video streaming) that host millions of users increasingly rely upon semi-structured super-P2P systems to provide efficient services in dynamic environments. Given the critical role of 'super peers' in such topologies, attackers target super peers due to the resultant high damage on P2P services. In this paper, we consider the prominent class of Outgoing Eclipse Attacks (OEA) where an attacker aims to block the communication by controlling all the outgoing connections of honest super peers. Our interest on OEA stems from the fact that our simulation studies reveal that OEAs can cause up to 90% of all service requests to fail. Our attack mitigation relies upon a novel (a) monitoring and (b) malicious peer eviction scheme based on a composite proactive and reactive mechanism. Our proactive mechanism enforces an upper bound on the number of connections an attacker can establish, whereas our reactive mechanism expels malicious peers from the overlay using a distributed consensus protocol. We show that our protection mechanism is highly effective and exhibits a low false-positive rate. Our extensive simulation study validates the analytical results over a large range of parameters with observed detection accuracies of 99% and throughput enhancements of up to 100% while entailing an overhead of less than 5%."
W,55,"An electronic toll collection (ETC) system is one of the most important parts of an intelligent transportation system (ITS), but existing ETC systems are not efficient and have vehicle fee evasion complications. Owing to the traceability and tamper resistance of a blockchain, the combination of a blockchain and ETC system is a feasible way to solve the above problems. However, traditional blockchain (e.g., Bitcoin and Ethereum) has high power consumption and low efficiency. Hence, it cannot be used in ETC systems with high throughput and is not suitable for power-constrained Internet of Things (IoT) devices. In this study, therefore, we propose a blockchain architecture for the ETC system. To curb vehicle fee evasion behavior, thereby reducing the economic loss caused, we propose a vehicle behavior management mechanism based on credit value. Furthermore, to reduce the burden of storage and build a chain of evidence for auditing purposes, we propose an evidence chain framework. To protect the data security in the transaction process, we designed a data protection method to encrypt the transaction data. Additionally, this system is based on an open-source alliance blockchain framework called Hyperledger Fabric, which is more in line with the current application scenarios of ETC systems. We implemented the system on a Raspberry Pi and carried out simulations. The comprehensive evaluation results and analysis show that the system effectively reduces the number of illegal acts, completes the evidence inspection, and improves the security of the data."
W,56,"Background Street imagery is a promising and growing big data source providing current and historical images in more than 100 countries. Studies have reported using this data to audit road infrastructure and other built environment features. Here we explore a novel application, using Google Street View (GSV) to predict travel patterns at the city level. Methods We sampled 34 cities in Great Britain. In each city, we accessed 2000 GSV images from 1000 random locations. We selected archived images from time periods overlapping with the 2011 Census and the 2011-2013 Active People Survey (APS). We manually annotated the images into seven categories of road users. We developed regression models with the counts of images of road users as predictors. The outcomes included Census-reported commute shares of four modes (combined walking plus public transport, cycling, motorcycle, and car), as well as APS-reported past-month participation in walking and cycling. Results We found high correlations between GSV counts of cyclists ('GSV-cyclists') and cycle commute mode share (r = 0.92)/past-month cycling (r = 0.90). Likewise, GSV-pedestrians was moderately correlated with past-month walking for transport (r = 0.46), GSV-motorcycles was moderately correlated with commute share of motorcycles (r = 0.44), and GSV-buses was highly correlated with commute share of walking plus public transport (r = 0.81). GSV-car was not correlated with car commute mode share (r = -0.12). However, in multivariable regression models, all outcomes were predicted well, except past-month walking. The prediction performance was measured using cross-validation analyses. GSV-buses and GSV-cyclists are the strongest predictors for most outcomes. Conclusions GSV images are a promising new big data source to predict urban mobility patterns. Predictive power was the greatest for those modes that varied the most (cycle and bus). With its ability to identify mode of travel and capture street activity often excluded in routinely carried out surveys, GSV has the potential to be complementary to new and traditional data. With half the world's population covered by street imagery, and with up to 10 years historical data available in GSV, further testing across multiple settings is warranted both for cross-sectional and longitudinal assessments."
W,57,"The whole world is facing the urgent issue of balancing economic development and ecological conservation. The fulfillment of the solution requires green innovation at the regional level. However, the heterogeneity of green innovation is obvious in different regions. To explore ways at effectively improving the level of regional green innovation in China, the research develops decomposition analysis based on the Logarithmic Mean Divisia Index (LMDI) model to identify the driving factors of green innovation. We also take the Geographical and Temporal Weighted Regression (GTWR) model to explore the driving factors of spatial-temporal heterogeneity of green innovation in China. The main results are as follows. Research and development (R&D) efficiency play a dominant role for increasing regional green patent applications, while environmental regulation contributes the most to a decline of regional green patent applications during 2003-2017. Various determinants of green patent applications exhibit spatial-temporal heterogeneity, such as the coefficients of influencing factors for each province in 2017 being more significant than the same coefficients in 2003. Beijing's coefficient of R&D efficiency is the largest, while the coefficient of economic development for Shanxi is the largest. The findings herein provide detailed insight for China's policymakers to effectively improve the level of regional green innovation domestically, which is of constructive significance to narrow the gap of regional green innovation and realize the coordinated and sustainable development of economy. (C) 2020 Elsevier Ltd. All rights reserved."
W,58,"Artificial general intelligence (AGI) progression metrics indicate AGI will occur within decades. No proof exists that AGI will benefit humans and not harm or eliminate humans. A set of logically distinct conceptual components is proposed that are necessary and sufficient to (1) ensure various AGI scenarios will not harm humanity, and (2) robustly align AGI and human values and goals. By systematically addressing pathways to malevolent AI we can induce the methods/axioms required to redress them. Distributed ledger technology (DLT, blockchain) is integral to this proposal, e.g., smart contracts are necessary to address the evolution of AI that will be too fast for human monitoring and intervention. The proposed axioms: (1) Access to technology by market license. (2) Transparent ethics embodied in DLT. (3) Morality encrypted via DLT. (4) Behavior control structure with values at roots. (5) Individual bar-code identification of critical components. (6) Configuration Item (from business continuity/disaster recovery planning). (7) Identity verification secured via DLT. (8) Smart automated contracts based on DLT. (9) Decentralized applications-AI software modules encrypted via DLT. (10) Audit trail of component usage stored via DLT. (11) Social ostracism (denial of resources) augmented by DLT petitions. (12) Game theory and mechanism design."
W,59,"Purpose The purpose of this paper is to better understand management accounting automation by exploring the programmability of management accounting work. Design/methodology/approach We build upon the literature on digitalization in management accounting and draw upon the pragmatic constructivist methodology to understand how digitalization takes place at the individual actors' level in accounting practice. The paper uses a data set from an interventionist case study of a machinery manufacturer. Findings We examine an actual process of automating management accounting tasks. During this development process, surprisingly, calculation tasks remained more fit for humans than machines though, initially, they were thought to be programmable. Research limitations/implications According to our findings, practitioners may interpret experts' nonprogrammable work tasks as programmable and seek to automate them. Only identifying the factual possibilities for automating accounting-related work can lead to automation-improved efficiency. Our findings can be increasingly relevant for advanced analytics initiatives and applications within management accounting (e.g. robotic process automation, big data, machine learning and artificial intelligence). Practical implications Practitioners need to carefully analyze the entity they wish to automate and understand the factual possibilities of using and maintaining the planned automatic system throughout its life cycle. Originality/value The paper shows that when processes are assessed from a distance, the nonprogrammable management accounting tasks and expertise can become misinterpreted as programmable, and the goal of automating them has little chance of success. It also shows possibilities for human accountants to remain relevant in comparison to machines and paves the way for further studies on advanced decision technologies in management accounting."
W,60,"Vulnerability detection is imperative to protect software systems from cyber attacks. However, existing methods either rely on experts to directly define vulnerability patterns or define vulnerability features and then use machine learning methods to generate vulnerability patterns automatically. It is not only a laborious task but will miss many vulnerabilities and incur a high false-positive rate. Besides, a large number of resources are required to audit the precise location of the vulnerability. To solve the problems, we propose AVDHRAM, a systematic Automated Vulnerability Detection framework based on Hierarchical Representation and Attention Mechanism. We use a deep learning network, Hierarchical Attention Network(HAN), to relieve human experts from the tedious task of manually defining features. The framework adds structural information in the process of source code representation using a finer granularity(slice), instead of function, file, or component. It can better represent vulnerabilities and learn more subtle vulnerability patterns to improve detection accuracy. Additionally, we use the attention mechanism to implement a convenient visualization tool, which can highlight the parts that have the most significant impact on the classification decision and speed up the process of vulnerability location analysis. Experimental results show that AVDHRAM outperforms the previous neural networks and other vulnerability detection methods in several metrics."
W,61,"Many important decisions historically made by people are now made by computers. Algorithms count votes, approve loan and credit card applications, target citizens or neighborhoods for police scrutiny, select taxpayers for IRS audit, grant or deny immigration visas, and more. The accountability mechanisms and legal standards that govern such decision processes have not kept pace with technology. The tools currently available to policymakers, legislators, and courts were developed to oversee human decisionmakers and often fail when applied to computers instead. For example, how do you judge the intent of a piece of software? Because automated decision systems can return potentially incorrect, unjustified, or unfair results, additional approaches are needed to make such systems accountable and governable. This Article reveals a new technological toolkit to verify that automated decisions comply with key standards of legal fairness. We challenge the dominant position in the legal literature that transparency will solve these problems. Disclosure of source code is often neither necessary (because of alternative techniques from computer science) nor sufficient (because of the issues analyzing code) to demonstrate the fairness of a process. Furthermore, transparency may be undesirable, such as when it discloses private information or permits tax cheats or terrorists to game the systems determining audits or security screening. The central issue is how to assure the interests of citizens, and society as a whole, in making these processes more accountable. This Article argues that technology is creating new opportunities-subtler and more flexible than total transparency-to design decisionmaking algorithms so that they better align with legal and policy objectives. Doing so will improve not only the current governance of automated decisions, but also-in certain cases-the governance of decisionmaking in general. The implicit (or explicit) biases of human decisionmakers can be difficult to find and root out, but we can peer into the brain of an algorithm: computational processes and purpose specifications can be declared prior to use and verified afterward. The technological tools introduced in this Article apply widely. They can be used in designing decisionmaking processes from both the private and public sectors, and they can be tailored to verify different characteristics as desired by decisionmakers, regulators, or the public. By forcing a more careful consideration of the effects of decision rules, they also engender policy discussions and closer looks at legal standards. As such, these tools have far-reaching implications throughout law and society. Part I of this Article provides an accessible and concise introduction to foundational computer science techniques that can be used to verify and demonstrate compliance with key standards of legal fairness for automated decisions without revealing key attributes of the decisions or the processes by which the decisions were reached. Part II then describes how these techniques can assure that decisions are made with the key governance attribute of procedural regularity, meaning that decisions are made under an announced set of rules consistently applied in each case. We demonstrate how this approach could be used to redesign and resolve issues with the State Department's diversity visa lottery. In Part III, we go further and explore how other computational techniques can assure that automated decisions preserve fidelity to substantive legal and policy choices. We show how these tools may be used to assure that certain kinds of unjust discrimination are avoided and that automated decision processes behave in ways that comport with the social or legal standards that govern the decision. We also show how automated decisionmaking may even complicate existing doctrines of disparate treatment and disparate impact, and we discuss some recent computer science work on detecting and removing discrimination in algorithms, especially in the context of big data and machine learning. And lastly, in Part IV, we propose an agenda to further synergistic collaboration between computer science, law, and policy to advance the design of automated decision processes for accountability."
W,62,"Mobile edge computing for autonomous driving needs to manage heterogeneous resources and process large amounts of data or multi-purpose payload. There needs to be deploying, scheduling and migrating tasks on edge nodes to ensure the reliability of tasks or maximize the utilization of resources. However, applying autonomous learning methods on autonomous driving is exceptionally difficult, due to the complexity of multi-dimensional context and the sensitivity to hyperparameters. In this paper, we propose a learning approach to quality-of-service (QoS) prediction of services via multi-dimensional context, and develop a stable approach for service deployment that requires minimal hyperparameter tuning and a modest number of trials to learn multilayer neural network policies. This approach can automatically trades off exploration against exploitation by automatically tuning hyperparameter based on maximum entropy reinforcement learning. We then demonstrate that this approach achieves state-of-the-art performance on Autoware benchmark environments."
